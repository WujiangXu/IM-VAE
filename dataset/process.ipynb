{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6cec997c-943e-4a14-91a4-b323e3808748",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2023-10-30T09:09:56.977701Z",
     "shell.execute_reply.started": "2023-10-30T09:08:43.779223Z",
     "to_execute": "2023-10-30T09:08:43.679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2360906 96828 3670742 1545746 55688 2360155\n",
      "34580 14240 146797\n",
      "23795 10907 143355\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def filter_data(filePath):\n",
    "    data = []\n",
    "    ratings = pd.read_csv(filePath, delimiter=\",\", encoding=\"latin1\")\n",
    "    '''\n",
    "       Notice: amazon 18 version ratings only order is different from 14 version.\n",
    "    '''\n",
    "    # ratings.columns = ['itemId' ,'userId', 'Rating', 'timesteamp'] # 18 version\n",
    "    ratings.columns = ['userId', 'itemId', 'Rating', 'timesteamp'] # 14 version\n",
    "    rate_size_dic_i = ratings.groupby('itemId').size()\n",
    "    # choosed_index_del_i = rate_size_dic_i.index[rate_size_dic_i < 10]\n",
    "    choosed_index_del_i = rate_size_dic_i.index[rate_size_dic_i < 10]\n",
    "    ratings = ratings[~ratings['itemId'].isin(list(choosed_index_del_i))] # item freq more than 10\n",
    "\n",
    "    user_unique = list(ratings['userId'].unique())\n",
    "    movie_unique = list(ratings['itemId'].unique())\n",
    "\n",
    "    u = len(user_unique)\n",
    "    i = len(movie_unique)\n",
    "    rating_num = len(ratings)\n",
    "    ratings = ratings.drop(columns=['timesteamp'])\n",
    "    return u, i, rating_num, user_unique, ratings\n",
    "\n",
    "def filter_user(ratings1, ratings2):\n",
    "    rate_size_dic_u1 = ratings1.groupby('userId').size()\n",
    "    rate_size_dic_u2 = ratings2.groupby('userId').size()\n",
    "    choosed_index_del_u1 = rate_size_dic_u1.index[rate_size_dic_u1 < 5]\n",
    "    choosed_index_del_u2 = rate_size_dic_u2.index[rate_size_dic_u2 < 5]\n",
    "    ratings1 = ratings1[~ratings1['userId'].isin(list(choosed_index_del_u1) + list(choosed_index_del_u2))]\n",
    "    ratings2 = ratings2[~ratings2['userId'].isin(list(choosed_index_del_u1) + list(choosed_index_del_u2))]\n",
    "    return ratings1, ratings2\n",
    "\n",
    "def filter_item(ratings1, ratings2):\n",
    "    rate_size_dic_u1 = ratings1.groupby('itemId').size()\n",
    "    rate_size_dic_u2 = ratings2.groupby('itemId').size()\n",
    "    choosed_index_del_u1 = rate_size_dic_u1.index[rate_size_dic_u1 < 5]\n",
    "    choosed_index_del_u2 = rate_size_dic_u2.index[rate_size_dic_u2 < 5]\n",
    "    ratings1 = ratings1[~ratings1['itemId'].isin(list(choosed_index_del_u1) + list(choosed_index_del_u2))]\n",
    "    ratings2 = ratings2[~ratings2['itemId'].isin(list(choosed_index_del_u1) + list(choosed_index_del_u2))]\n",
    "    return ratings1, ratings2\n",
    "\n",
    "def reindex_ratings(ratings1,ratings2):\n",
    "    user_unique1 = list(ratings1['userId'].unique())\n",
    "    user_unique2 = list(ratings2['userId'].unique())\n",
    "    item_unique1 = list(ratings1['itemId'].unique())\n",
    "    item_unique2 = list(ratings2['itemId'].unique())\n",
    "    user_dict = dict()\n",
    "    item_dict = dict()\n",
    "    for i in range(len(user_unique1)):\n",
    "        user_dict[user_unique1[i]] = i\n",
    "    for i in range(len(user_unique2)):\n",
    "        user_dict[user_unique2[i]] = i + len(user_dict)\n",
    "    for i in range(len(item_unique1)):\n",
    "        item_dict[item_unique1[i]] = i\n",
    "    for i in range(len(item_unique2)):\n",
    "        item_dict[item_unique2[i]] = i + len(item_dict)\n",
    "    ratings1['userId'] = ratings1['userId'].apply(lambda x :user_dict[x])\n",
    "    ratings2['userId'] = ratings2['userId'].apply(lambda x :user_dict[x])\n",
    "    ratings1['itemId'] = ratings1['itemId'].apply(lambda x :item_dict[x])\n",
    "    ratings2['itemId'] = ratings2['itemId'].apply(lambda x :item_dict[x])\n",
    "    print(\"all user number :{}, item number :{}\".format(len(user_dict),len(item_dict)))\n",
    "    return ratings1,ratings2\n",
    "    \n",
    "def find_dict(ratings):\n",
    "    seq = defaultdict(list)  \n",
    "    uid = ratings['userId'].tolist()\n",
    "    iid = ratings['itemId'].tolist()\n",
    "    for i in range(len(uid)):\n",
    "        seq[uid[i]].append(iid[i])\n",
    "    return seq\n",
    "\n",
    "# music domain 0 movie domain 1 all filter user number :110073, item number :44741\n",
    "music_csv = \"/ossfs/workspace/NMCDR/MRHG/amazon/ratings_Clothing_Shoes_and_Jewelry.csv\"#\"/ossfs/workspace/MRHG/amazon/ratings_Cell_Phones_and_Accessories.csv\"#\"/ossfs/workspace/MRHG/amazon/ratings_Clothing_Shoes_and_Jewelry.csv\"#\"/ossfs/workspace/MRHG/amazon/ratings_Digital_Music.csv\"\n",
    "movie_csv = \"/ossfs/workspace/NMCDR/MRHG/amazon/ratings_Sports_and_Outdoors.csv\"#\"/ossfs/workspace/MRHG/amazon/ratings_Electronics.csv\"#\"/ossfs/workspace/MRHG/amazon/ratings_Sports_and_Outdoors.csv\"#\"/ossfs/workspace/MRHG/amazon/ratings_Movies_and_TV.csv\"\n",
    "u1, i1, rating_num1, user_unique1, ratings1 = filter_data(music_csv)\n",
    "u2, i2, rating_num2, user_unique2, ratings2 = filter_data(movie_csv)\n",
    "print(u1,i1,rating_num1,u2,i2,rating_num2)\n",
    "\n",
    "ratings1 = ratings1.loc[ratings1['Rating']>=3.0]\n",
    "ratings2 = ratings2.loc[ratings2['Rating']>=3.0]\n",
    "\n",
    "ratings1, ratings2 = filter_user(ratings1, ratings2) # del overlap user < 5\n",
    "ratings1, ratings2 = filter_item(ratings1, ratings2) # del overlap user < 5\n",
    "# print(len(ratings1),len(ratings2))\n",
    "\n",
    "ratings1 = ratings1.loc[ratings1['Rating']>=3.0]\n",
    "ratings1 = ratings1.drop(columns=['Rating'])\n",
    "ratings2 = ratings2.loc[ratings2['Rating']>=3.0]\n",
    "ratings2 = ratings2.drop(columns=['Rating'])\n",
    "print(len(list(ratings1['userId'].unique())),len(list(ratings1['itemId'].unique())),len(ratings1))\n",
    "print(len(list(ratings2['userId'].unique())),len(list(ratings2['itemId'].unique())),len(ratings2))\n",
    "# print(len(ratings1),len(ratings2)) # paper dataset anlysis here 80% for train 20% for test\n",
    "\n",
    "# print(ratings1)\n",
    "# print(ratings2)\n",
    "# ratings1,ratings2 = reindex_ratings(ratings1,ratings2)\n",
    "# print(ratings1,ratings2)\n",
    "\n",
    "seq1 = find_dict(ratings1)\n",
    "seq2 = find_dict(ratings2)\n",
    "# print(seq1,seq2)\n",
    "user_unique1 = list(ratings1['userId'].unique())\n",
    "user_unique2 = list(ratings2['userId'].unique())\n",
    "user_node,seq_d1, seq_d2, domain_id  = [], [], [], []\n",
    "\n",
    "for u_id_tmp in user_unique1:\n",
    "    if len(seq1[u_id_tmp])>=2 and (len(seq2[u_id_tmp])>=2 or len(seq2[u_id_tmp])==0):\n",
    "        user_node.append(u_id_tmp)\n",
    "        seq_d1.append(seq1[u_id_tmp])\n",
    "        seq_d2.append(seq2[u_id_tmp])\n",
    "        domain_id.append(0)\n",
    "\n",
    "for u_id_tmp in user_unique2:\n",
    "    if len(seq2[u_id_tmp])>=2 and (len(seq1[u_id_tmp])>=2 or len(seq1[u_id_tmp])==0):\n",
    "        user_node.append(u_id_tmp)\n",
    "        seq_d1.append(seq1[u_id_tmp])\n",
    "        seq_d2.append(seq2[u_id_tmp])\n",
    "        domain_id.append(1)\n",
    "        \n",
    "from itertools import chain\n",
    "flattened_list = list(chain(*(seq_d1+seq_d2)))\n",
    "# dataframe.to_csv(save_csv_name,index=0001393774False,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f841857e-d106-42c2-ad67-989f2274f321",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2023-10-30T09:11:34.165172Z",
     "shell.execute_reply.started": "2023-10-30T09:11:32.337946Z",
     "to_execute": "2023-10-30T09:11:32.220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54636\n",
      "       user_id                                           seq_d1  \\\n",
      "0            0         [22880, 7761, 5160, 15323, 10871, 16290]   \n",
      "1            1           [22880, 17201, 4917, 2139, 6704, 8384]   \n",
      "2            2    [22880, 15289, 1803, 14388, 10117, 9937, 867]   \n",
      "3            3                             [22880, 20298, 8084]   \n",
      "4            4                [22880, 9573, 6771, 13616, 11694]   \n",
      "...        ...                                              ...   \n",
      "54631    47149                                               []   \n",
      "54632    47150                                               []   \n",
      "54633    31846                                   [21908, 12618]   \n",
      "54634    27631  [13584, 19336, 23854, 10749, 2336, 8651, 18117]   \n",
      "54635    47151                                               []   \n",
      "\n",
      "                                        seq_d2  domain_id  \n",
      "0                                           []          0  \n",
      "1                                [8139, 11426]          0  \n",
      "2                                           []          0  \n",
      "3                                           []          0  \n",
      "4                                [20253, 2606]          0  \n",
      "...                                        ...        ...  \n",
      "54631               [22497, 4685, 9812, 17864]          1  \n",
      "54632         [13368, 8233, 1704, 1689, 17171]          1  \n",
      "54633                       [6700, 7689, 4421]          1  \n",
      "54634  [12013, 16405, 23986, 9889, 9879, 9713]          1  \n",
      "54635                             [8716, 4421]          1  \n",
      "\n",
      "[54636 rows x 4 columns]\n",
      "24387 15281 14968\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.DataFrame({'user_id':user_node,'seq_d1':seq_d1,'seq_d2':seq_d2,'domain_id':domain_id})\n",
    "print(len(dataframe))\n",
    "user_unique1 = list(dataframe['user_id'].unique())\n",
    "user_dict = dict()\n",
    "for i in range(len(user_unique1)):\n",
    "    user_dict[user_unique1[i]] = i\n",
    "dataframe['user_id'] = dataframe['user_id'].apply(lambda x :user_dict[x])\n",
    "\n",
    "item_unique = list(dataframe['seq_d1']) + list(dataframe['seq_d2'])\n",
    "item_set = set(list(chain(*item_unique)))\n",
    "item_hash_dict = dict()\n",
    "i = 0 \n",
    "for j in item_set:\n",
    "    item_hash_dict[j] = i\n",
    "    i += 1\n",
    "\n",
    "def get_item_hash(item):\n",
    "    return [item_hash_dict[i] for i in item]\n",
    "dataframe['seq_d1'] = dataframe['seq_d1'].apply(get_item_hash)\n",
    "dataframe['seq_d2'] = dataframe['seq_d2'].apply(get_item_hash)\n",
    "print(dataframe)\n",
    "\n",
    "dataframe2 = dataframe\n",
    "df_d1 = dataframe2[dataframe2['seq_d2'].apply(lambda x: len(x) == 0)]\n",
    "# df_d1 = df_d1[df_d1['seq_d1'].apply(lambda x: len(x)>15 and len(x)<40 )]\n",
    "df_d2 = dataframe2[dataframe2['seq_d1'].apply(lambda x: len(x) == 0)]\n",
    "# df_d2 = df_d2[df_d2['seq_d2'].apply(lambda x: len(x)>15 and len(x)<40)]\n",
    "df_both_t = dataframe2[dataframe2['seq_d1'].apply(lambda x: len(x) > 0)]\n",
    "df_both = df_both_t[df_both_t['seq_d2'].apply(lambda x: len(x) > 0)]\n",
    "# df_both = df_both[df_both['seq_d1'].apply(lambda x: len(x)>15 and len(x)<40 )]\n",
    "# df_both = df_both[df_both['seq_d2'].apply(lambda x: len(x)>15 and len(x)<40 )]\n",
    "print(len(df_d1),len(df_d2),len(df_both))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c68adc1a-5eed-4f54-9ec6-ef80ded309c3",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2023-10-30T09:11:58.054254Z",
     "shell.execute_reply.started": "2023-10-30T09:11:58.038040Z",
     "to_execute": "2023-10-30T09:11:57.958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8048 7640 7484\n"
     ]
    }
   ],
   "source": [
    "#random select 20000 15000 10000\n",
    "df_d1 = df_d1.sample(frac=0.33, random_state=1)\n",
    "df_d2 = df_d2.sample(frac=0.50, random_state=1)\n",
    "df_both = df_both.sample(frac=0.50, random_state=1)\n",
    "print(len(df_d1),len(df_d2),len(df_both))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40104e21-5518-4b0d-8bb8-6b40955e68f6",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2023-10-30T09:12:03.336960Z",
     "shell.execute_reply.started": "2023-10-30T09:12:02.237613Z",
     "to_execute": "2023-10-30T09:12:02.141Z"
    }
   },
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_d1, df_d2, df_both], ignore_index=True)\n",
    "df_all.to_csv(\"/ossfs/workspace/VAE_CDR/dataset/cloth_sport_all.csv\")\n",
    "\n",
    "data = df_all.sample(frac=1.0)\n",
    "train_len = int(data.shape[0] * 0.80)\n",
    "save_data_train = data.iloc[ : train_len]\n",
    "save_data_val = data.iloc[ train_len: ]\n",
    "train_name = \"/ossfs/workspace/VAE_CDR/dataset/cloth_sport_train.csv\"\n",
    "val_name = \"/ossfs/workspace/VAE_CDR/dataset/cloth_sport_test.csv\"\n",
    "save_data_train.to_csv(train_name, index=False)\n",
    "save_data_val.to_csv(val_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aed5acc1-a7e6-4b6f-8d04-0e7109e9794d",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2023-10-30T09:12:11.176949Z",
     "shell.execute_reply.started": "2023-10-30T09:12:10.769378Z",
     "to_execute": "2023-10-30T09:12:10.705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1542 3093\n",
      "308\n"
     ]
    }
   ],
   "source": [
    "# generate cold-start users\n",
    "import os\n",
    "import random\n",
    "from typing import DefaultDict\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import json\n",
    "from random import sample\n",
    "def select_overlap_user_csu(df,save_train_name,overlap_ratio):\n",
    "    data = df\n",
    "    user_node = data['user_id'].tolist()\n",
    "    seq_d1 = data['seq_d1'].tolist()\n",
    "    seq_d2 = data['seq_d2'].tolist()\n",
    "    domain_id = data['domain_id'].tolist()\n",
    "    user_node_overlap,seq_d1_overlap, seq_d2_overlap, domain_id_overlap  = [], [], [], []\n",
    "    user_node_nolap,seq_d1_nolap, seq_d2_nolap, domain_id_nolap  = [], [], [], []\n",
    "    user_node_new, seq_d1_new, seq_d2_new, domain_id_new = [], [], [], []\n",
    "    for i in range(len(user_node)):\n",
    "        seq1_tmp = json.loads(seq_d1[i])\n",
    "        seq2_tmp = json.loads(seq_d2[i])\n",
    "        if len(seq1_tmp)!=0 and len(seq2_tmp)!=0:\n",
    "            user_node_overlap.append(user_node[i])\n",
    "            seq_d1_overlap.append(seq1_tmp)\n",
    "            seq_d2_overlap.append(seq2_tmp)\n",
    "            domain_id_overlap.append(domain_id[i])\n",
    "        else :\n",
    "            user_node_nolap.append(user_node[i])\n",
    "            seq_d1_nolap.append(seq1_tmp)\n",
    "            seq_d2_nolap.append(seq2_tmp)\n",
    "            domain_id_nolap.append(domain_id[i])\n",
    "    print(len(user_node_overlap),len(user_node_nolap)) # 3384 69945\n",
    "    #nolap_num = int(len(user_node_overlap)/overlap_ratio-len(user_node_overlap)) # 3384 + \n",
    "    sample_overlap_num = int(len(user_node_overlap)*overlap_ratio)\n",
    "    idx_lst = [i for i in range(len(user_node_overlap))]\n",
    "    select_idx = sample(idx_lst, sample_overlap_num)\n",
    "    print(sample_overlap_num)\n",
    "    # print(select_idx)\n",
    "    for i in range(len(user_node_overlap)):\n",
    "        if i in select_idx: # cold-start users\n",
    "            if domain_id_overlap[i]==0:\n",
    "                user_node_new.append(user_node_overlap[i])\n",
    "                seq_d1_new.append(seq_d1_overlap[i][-1:])\n",
    "                seq_d2_new.append(seq_d2_overlap[i])\n",
    "                domain_id_new.append(domain_id_overlap[i])\n",
    "            else:\n",
    "                user_node_new.append(user_node_overlap[i])\n",
    "                seq_d1_new.append(seq_d1_overlap[i])\n",
    "                seq_d2_new.append(seq_d2_overlap[i][-1:])\n",
    "                domain_id_new.append(domain_id_overlap[i])   \n",
    "        else:\n",
    "            user_node_new.append(user_node_overlap[i])\n",
    "            seq_d1_new.append(seq_d1_overlap[i])\n",
    "            seq_d2_new.append(seq_d2_overlap[i])\n",
    "            domain_id_new.append(domain_id_overlap[i])\n",
    "\n",
    "    sample_nolap_num = int(len(user_node_nolap)*overlap_ratio)\n",
    "    idx_lst2 = [i for i in range(len(user_node_nolap))]\n",
    "    select_idx2 = sample(idx_lst2, sample_nolap_num)\n",
    "    for i in range(len(user_node_nolap)):\n",
    "        if i in select_idx: # cold-start users\n",
    "            if domain_id_nolap[i]==0:\n",
    "                user_node_new.append(user_node_nolap[i])\n",
    "                seq_d1_new.append(seq_d1_nolap[i][-1:])\n",
    "                seq_d2_new.append(seq_d2_nolap[i])\n",
    "                domain_id_new.append(domain_id_nolap[i])\n",
    "            else:\n",
    "                user_node_new.append(user_node_nolap[i])\n",
    "                seq_d1_new.append(seq_d1_nolap[i])\n",
    "                seq_d2_new.append(seq_d2_nolap[i][-1:])\n",
    "                domain_id_new.append(domain_id_nolap[i])   \n",
    "        else:\n",
    "            user_node_new.append(user_node_nolap[i])\n",
    "            seq_d1_new.append(seq_d1_nolap[i])\n",
    "            seq_d2_new.append(seq_d2_nolap[i])\n",
    "            domain_id_new.append(domain_id_nolap[i])\n",
    "    \n",
    "    dataframe = pd.DataFrame({'user_id':user_node_new,'seq_d1':seq_d1_new,'seq_d2':seq_d2_new,'domain_id':domain_id_new})\n",
    "    dataframe.to_csv(save_train_name,index=False,sep=',')\n",
    "\n",
    "save_data_val  = pd.read_csv(\"/ossfs/workspace/VAE_CDR/dataset/cloth_sport_test.csv\")\n",
    "ratio = 0.20\n",
    "csu_name = \"/ossfs/workspace/VAE_CDR/dataset/cloth_sport_test_csu.csv\"\n",
    "test_csu = select_overlap_user_csu(save_data_val,csu_name,ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a063b03-3717-4bed-a42f-2938998a5432",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2023-10-30T09:12:18.904978Z",
     "shell.execute_reply.started": "2023-10-30T09:12:18.550344Z",
     "to_execute": "2023-10-30T09:12:18.468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24506\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"/ossfs/workspace/VAE_CDR/dataset/cloth_sport_all.csv\")\n",
    "import json\n",
    "\n",
    "df['seq_d1'] = df['seq_d1'].apply(json.loads)\n",
    "df['seq_d2'] = df['seq_d2'].apply(json.loads)\n",
    "\n",
    "\n",
    "item_unique2 = list(df['seq_d1'].tolist()) + list(df['seq_d2'].tolist())  \n",
    "item_set2 = set(list(chain(*item_unique2)))\n",
    "print(max(item_set2))\n",
    "#phone_elec 40717\n",
    "#cloth_sport 24506"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
